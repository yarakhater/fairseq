/mnt/beegfs/home/khater/.local/lib/python3.7/site-packages/torch/cuda/__init__.py:145: UserWarning: 
RTX A6000 with CUDA capability sm_86 is not compatible with the current PyTorch installation.
The current PyTorch install supports CUDA capabilities sm_37 sm_50 sm_60 sm_70.
If you want to use the RTX A6000 GPU with PyTorch, please check the instructions at https://pytorch.org/get-started/locally/

  warnings.warn(incompatible_device_warn.format(device_name, capability, " ".join(arch_list), device_name))
Traceback (most recent call last):
  File "train.py", line 14, in <module>
    cli_main()
  File "/mnt/beegfs/projects/interpretable-nn/stage/fairseq/fairseq_cli/train.py", line 557, in cli_main
    distributed_utils.call_main(cfg, main)
  File "/mnt/beegfs/projects/interpretable-nn/stage/fairseq/fairseq/distributed/utils.py", line 369, in call_main
    main(cfg, **kwargs)
  File "/mnt/beegfs/projects/interpretable-nn/stage/fairseq/fairseq_cli/train.py", line 190, in main
    valid_losses, should_stop = train(cfg, trainer, task, epoch_itr)
  File "/mnt/beegfs/home/khater/anaconda3/lib/python3.7/contextlib.py", line 74, in inner
    return func(*args, **kwds)
  File "/mnt/beegfs/projects/interpretable-nn/stage/fairseq/fairseq_cli/train.py", line 316, in train
    log_output = trainer.train_step(samples)
  File "/mnt/beegfs/home/khater/anaconda3/lib/python3.7/contextlib.py", line 74, in inner
    return func(*args, **kwds)
  File "/mnt/beegfs/projects/interpretable-nn/stage/fairseq/fairseq/trainer.py", line 856, in train_step
    raise e
  File "/mnt/beegfs/projects/interpretable-nn/stage/fairseq/fairseq/trainer.py", line 830, in train_step
    **extra_kwargs,
  File "/mnt/beegfs/projects/interpretable-nn/stage/fairseq/fairseq/tasks/fairseq_task.py", line 512, in train_step
    loss, sample_size, logging_output = criterion(model, sample)
  File "/mnt/beegfs/home/khater/.local/lib/python3.7/site-packages/torch/nn/modules/module.py", line 1110, in _call_impl
    return forward_call(*input, **kwargs)
  File "/mnt/beegfs/projects/interpretable-nn/stage/fairseq/fairseq/criterions/cross_entropy.py", line 35, in forward
    net_output = model(**sample["net_input"])
  File "/mnt/beegfs/home/khater/.local/lib/python3.7/site-packages/torch/nn/modules/module.py", line 1110, in _call_impl
    return forward_call(*input, **kwargs)
  File "/mnt/beegfs/projects/interpretable-nn/stage/fairseq/fairseq/models/fairseq_model.py", line 322, in forward
    encoder_out = self.encoder(src_tokens, src_lengths=src_lengths, **kwargs)
  File "/mnt/beegfs/home/khater/.local/lib/python3.7/site-packages/torch/nn/modules/module.py", line 1110, in _call_impl
    return forward_call(*input, **kwargs)
  File "/mnt/beegfs/projects/interpretable-nn/stage/fairseq/fairseq/models/fconv.py", line 243, in forward
    x = self.embed_tokens(src_tokens) + self.embed_positions(src_tokens)
  File "/mnt/beegfs/home/khater/.local/lib/python3.7/site-packages/torch/nn/modules/module.py", line 1110, in _call_impl
    return forward_call(*input, **kwargs)
  File "/mnt/beegfs/home/khater/.local/lib/python3.7/site-packages/torch/nn/modules/sparse.py", line 160, in forward
    self.norm_type, self.scale_grad_by_freq, self.sparse)
  File "/mnt/beegfs/home/khater/.local/lib/python3.7/site-packages/torch/nn/functional.py", line 2183, in embedding
    return torch.embedding(weight, input, padding_idx, scale_grad_by_freq, sparse)
RuntimeError: CUDA error: no kernel image is available for execution on the device
CUDA kernel errors might be asynchronously reported at some other API call,so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1.
